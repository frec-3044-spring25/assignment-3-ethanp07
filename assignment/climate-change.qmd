---
title: "Climate Change Module"
author: 'Ethan Pham'
format:
  html:
    embed-resources: true
---

```{r message=FALSE}
library(tidyverse)
```

## Warm-up: Examining CO2 trends in R

- Example from <http://climate.nasa.gov/vital-signs/carbon-dioxide/>
- Raw data from <https://gml.noaa.gov/webdata/ccgg/trends/co2/co2_mm_mlo.txt>

In 1958, Dr. Charles David Keeling (1928-2005), a scientist at Scripps Institute of Oceanography, began collecting data on atmospheric CO2 concentration at the Mauna Loa Observatory located in Hawaii. This dataset allowed us to understand the degree to which climate change is human-caused through our burning of fossil fuels and release of CO2 into the atmosphere. Due to his scientific achievements, Dr. Keeling was awarded the National Medal of Science by President George W. Bush in 2002. This is the highest award for lifetime scientific achievement that can be granted in the U.S. Today, you get to analyze this same dataset, except that you have more data than was available to Dr. Keeling and his colleagues because your dataset extends up to the current time.

To read the code, you will use a new function called `read_table`.  It is similar to `read_csv` except it looks for spaces between column entries rather than commas (remember that csv stands for comma-separated values).  Others include `read_tsv`, which uses tabs to separate entries.  You can discover the separation type by putting <https://gml.noaa.gov/webdata/ccgg/trends/co2/co2_mm_mlo.txt> into your web browser and examining the file.  The code also includes an argument for comment, which denotes the character used to define a line in the file as being a comment rather than data or a header.  The file also reveals that the column headers are on lines with a comment character, so they won't be read.  You will use the argument `col_names` to define the headers manually.  Finally, `NA` values are defined by the numbers -1 and -99, so they need to be defined using the `na` argument (otherwise, they will be read as numeric values).

```{r message=FALSE}
library(tidyverse)
co2 <-  read_table("https://gml.noaa.gov/webdata/ccgg/trends/co2/co2_mm_mlo.txt", 
                  comment="#",
                  col_names = c("year", "month", "decimal_date",
                                "monthly_average",
                                "deseasonalized", "days", "sd_days",
                                "unc_month_mean"),
                  na = c("-1", "-99.99"))
co2
```


```{r}
library(ggplot2)
ggplot(co2, aes(x = decimal_date, y = monthly_average)) + 
  geom_line() + 
  geom_line(aes(y = deseasonalized), color = "blue") +
  labs(x = "Year", y = "CO2 concentration (ppm)")
```

**Question 1:**

Describe the overall trend in the CO2 data.

**Answer 1:**

From the plot we can see that as time has passed the amount of CO2 concentration has steadily increased. The plot shows a linear relationship between year and CO2 concentration.

**Question 2:**

How does CO2 vary within a year?  What month is it at max?  Min?  What might explain this sub-annual pattern? (you will need to write code and make a plot to answer this question)

**Answer 2:**

```{r}
# Load necessary libraries
library(ggplot2)

# Compute the average CO2 for each month across all years
monthly_co2 <- co2 %>%
  group_by(month) %>%
  summarise(mean_co2 = mean(monthly_average, na.rm = TRUE))

# Find the months with max and min CO2
max_month <- monthly_co2$month[which.max(monthly_co2$mean_co2)]
min_month <- monthly_co2$month[which.min(monthly_co2$mean_co2)]

cat("Month with max CO2:", max_month, "\n")
cat("Month with min CO2:", min_month, "\n")

ggplot(co2, aes(x = factor(month), y = monthly_average)) +
  geom_boxplot(fill = "steelblue", alpha = 0.7, outlier.color = "red") +
  labs(title = "Monthly CO2 Distribution",
       x = "Month",
       y = "CO2 Concentration (ppm)") +
  theme_minimal()
```

CO2 is at its max in May and at its lowest in September. Throughout the year the CO2 values seems to stay mostly the same with the values going up during the spring months and then they start to decrease during the fall months. The higher CO2 values in the spring are most likely due to the fact that plants have not yet fully absorbed CO2 which would cause higher values of CO2 in the air. On the other hand, the lower values of CO2 in the fall are most likely due to plants have absorbed lots of CO2 at the peak of their growing season.

## Global Temperature Data

Current climate change affects many aspects of the environment, with socio-economic consequences. For example, a warmer climate can allow new diseases to be introduced and persist (e.g., West Nile became established in the United States after an unusually warm winter, which allowed the mosquitoes that carry the virus to survive and spread). We are concerned not only with the actual temperature but also with the rate at which it changes. Rapid changes make it more likely that species cannot adapt and will go extinct. 

Each of the most recent years has been the warmest on record. In this section, we will analyze global mean temperature data.

Data from: <https://climate.nasa.gov/vital-signs/global-temperature/>

**Question 3:**

Describe the data set to the best of your ability, given the documentation provided. 

- Where is the data from?
- Describe the class of each column and what units it is measured in. 
- What is the difference between "global temperature" and "global temperature anomaly"? 

**Answer 3:**

The data is from NASA's Goddard Institute for Space Studies. It is part of NASA's GISTEMP (GISS Surface Temperature Analysis), a dataset that tracks global temperature anomalies. The dataset provides temperature anomaly estimates based on land and ocean data from 1880 to the present. The classes of all the columns should be numeric as we are working with temperature data. The units for the columns are degrees celcius. The global temperature is the actual temperature of the earth while the global temperature anomaly is the deviation from the long-term baseline average.

**Question 4:**

Construct the necessary R code to import and prepare for plotting the following data set: <https://data.giss.nasa.gov/gistemp/graphs/graph_data/Global_Mean_Estimates_based_on_Land_and_Ocean_Data/graph.txt>

You'll need to determine the file's delimiter and any comments or skips. You will also need to be sure that you have column names. You will not directly use the code above to read the CO2 data, but that code provides helpful tips for reading the data.

**Answer 4:**

```{r}
# Define the dataset URL
url <- "https://data.giss.nasa.gov/gistemp/graphs/graph_data/Global_Mean_Estimates_based_on_Land_and_Ocean_Data/graph.txt"

# Read the data, skipping metadata rows
temperature_data <- read_table(url, skip = 5, col_names = c("Year", "No_Smoothing", "Lowess_5"))

# View first few rows
head(temperature_data)
```

**Question 5:**

Plot the trend in global mean temperatures over time.  Describe what you see in the plot and how you interpret the patterns you observe.

**Answer 5:**

```{r}
ggplot(temperature_data, aes(x = Year)) +
  geom_line(aes(y = No_Smoothing), color = "red", size = 1, alpha = 0.7) +
  geom_line(aes(y = Lowess_5), color = "blue", size = 1, linetype = "dashed") +
  labs(title = "Global Temperature Anomaly Over Time (NASA GISTEMP)",
       x = "Year",
       y = "Temperature Anomaly (°C)",
       caption = "Data Source: NASA GISS") +
  theme_minimal()
```

The plot shows the global temperature anomalies from 1880 to 2024. The red line represents annual temperature anomalies without smoothing and the blue dashed line represents a LOESS (5-year smoothed) trend. After 1950 there is a consistent upward trend in temperature and then post 1980s there is a big increase in the rate of warming. In recent years there have been record-breaking anomalies exceeding +1.2°C. While early fluctuations appear due to natural climate variability, the post-1950 warming trend aligns with increased industrialization and greenhouse gas emissions. The sharp rise after 1980 and record-breaking anomalies in recent years confirm the acceleration of global warming. This pattern strongly suggests that human activity is a major driver of climate change.


## Evaluating the evidence for a "Pause" in warming?

The [2013 IPCC Report](https://www.ipcc.ch/pdf/assessment-report/ar5/wg1/WG1AR5_SummaryVolume_FINAL.pdf) included a tentative observation of a "much smaller increasing trend" in global mean temperatures since 1998 than was observed previously.  This led to much discussion in the media about the existence of a "Pause" or "Hiatus" in global warming rates, as well as much research looking into where the extra heat could have gone.  (Examples discussing this question include articles in [The Guardian](http://www.theguardian.com/environment/2015/jun/04/global-warming-hasnt-paused-study-finds), [BBC News](http://www.bbc.com/news/science-environment-28870988), and [Wikipedia](https://en.wikipedia.org/wiki/Global_warming_hiatus)). 

You will use rolling averages to help you explore the evidence for a pause. Since you have not been provided instructions for calculating rolling means, the learning objective of this question is to practice finding the solution.

**Question 6:**

Use a search engine (e.g., Google) or a chat LLM to find out how to calculate a rolling average in R. What search term or chat LLM prompt did you use?  What website or answer from the chat LLM did you end up using?  How much did you need to modify the code from the website or chat LLM to answer the question successfully?

**Answer 6:**

I used chatGPT to learn how to caluculate how to calculate a rolling average. It recommends to use the zoo package which has the rollmean() function in it. I did not have to change the code much for it to work in my answer. 

**Question 7:**

- What is the meaning of "5-year average" vs. "annual average"?
- Create a data frame from the annual temperature anomaly data (from Question 4) with three new columns: 5-year running averages, 10-year running averages, and 20-year running averages.

**Answer 7:**

```{r}
library(zoo)

# Define rolling window sizes
window_5 <- 5
window_10 <- 10
window_20 <- 20

# Compute rolling means (moving averages)
temperature_data <- temperature_data %>%
  mutate(
    Rolling_5yr = rollmean(No_Smoothing, k = window_5, fill = NA, align = "right"),
    Rolling_10yr = rollmean(No_Smoothing, k = window_10, fill = NA, align = "right"),
    Rolling_20yr = rollmean(No_Smoothing, k = window_20, fill = NA, align = "right")
  )

# Display the first few rows
head(temperature_data)
```

The annual average represents the temperature anomaly for just a single year while a 5-year running average smooths these fluctuations by averaging the last 5 years. The annual average captures short-term fluctuations due to nature vairability such as El Niño and volcanic eruptions. A 5-year running average makes long-term climate trends more visible. Longer running averages, such as 10-year and 20-year averages, further reduce noise, helping to highlight sustained warming patterns.

**Question 8:**

Plot the different averages on the *same plot* and describe what differences you see and why.  

**Answer 8:**

```{r}
# Plot all averages on the same graph
ggplot(temperature_data, aes(x = Year)) +
  geom_line(aes(y = No_Smoothing, color = "Annual Mean"), alpha = 0.5) +
  geom_line(aes(y = Rolling_5yr, color = "5-Year Average"), size = 1) +
  geom_line(aes(y = Rolling_10yr, color = "10-Year Average"), size = 1.2) +
  geom_line(aes(y = Rolling_20yr, color = "20-Year Average"), size = 1.5) +
  labs(title = "Global Temperature Anomalies with Running Averages",
       x = "Year",
       y = "Temperature Anomaly (°C)",
       color = "Legend",
       caption = "Data Source: NASA GISS") +
  scale_color_manual(values = c("Annual Mean" = "gray", 
                                "5-Year Average" = "blue", 
                                "10-Year Average" = "green", 
                                "20-Year Average" = "red")) +
  theme_minimal()
```

The plot shows that annual temperature anomalies (gray) fluctuate significantly, making it hard to see long-term trends. The 5-year average (blue) smooths some variations but still follows short-term fluctuations, while the 10-year (green) and 20-year (red) averages provide a clearer view of long-term warming. The 20-year average is the smoothest, revealing a consistent upward trend in global temperatures since the mid-20th century. Overall, all running averages confirm a significant long-term warming pattern despite short-term variability.

**Question 9:**

By examining the data here, what evidence do you find or not find for such a pause? 

**Answer 9:**

By examining the data, there is no clear evidence of a significant "pause" in global warming. While the annual temperature anomalies (gray) show short-term fluctuations, the 5-year (blue), 10-year (green), and 20-year (red) running averages reveal a consistent upward trend, particularly after the mid-20th century. Although some periods (e.g., early 2000s) may exhibit slower warming rates, the longer-term trends do not indicate a sustained pause. Instead, the overall pattern supports continued global warming, with temperature anomalies reaching record highs in recent years.

## Longer term trends in CO2 Records

When analyzing Earth’s climate, it is important to remember that Earth is 4.54 billion years old. Our analyses so far have only looked at recent history. How can we compare the recent data to prehistoric times? Are the current rates of change similar or different from those the earth has experienced in the past? To explore this, we can use data from ice cores drilled at the poles. 

Hundreds of ice cores have been extracted from polar ice because they contain valuable data on atmospheric chemistry over pre-historic times. These valuable data exist in tiny air bubbles trapped in the ice. These air bubbles contain the same gases in the same ratios as the atmosphere at the time when the ice formed. The data you will analyze today are from ice cores extracted from the Vostok research station in Antarctica. As you have probably assumed, the depth of the ice core is related to how old the ice is; deep ice is older. There are two other variables that you will be analyzing from the ice cores.  You will analyze CO2 concentration, which has been measured from air bubbles trapped in the ice. We can use these data to see what rates of change were like during this pre-historic period, during which human activity was minimal. 

[Ice core data](https://data.ess-dive.lbl.gov/view/doi%3A10.3334%2FCDIAC%2FATG.009):

Vostok Core, back to 400,000 years before the present day 

- Description of data set: <https://data.ess-dive.lbl.gov/view/doi%3A10.3334%2FCDIAC%2FATG.009>
- data: <https://data.ess-dive.lbl.gov/catalog/d1/mn/v2/object/ess-dive-457358fdc81d3a5-20180726T203952542>

You will use this code to download the data to your computer.

```{r}
download.file("https://data.ess-dive.lbl.gov/catalog/d1/mn/v2/object/ess-dive-457358fdc81d3a5-20180726T203952542",
              destfile = "vostok.icecore.co2")
```

You can click on the file in your Files pane to view it before reading into R.


**Question 10:**

The broad question is: how do recent atmospheric CO2 levels compare to historical levels?

Your answer to Question 10 is going to be a mix of code chunks and text that you put below in "Answer 10:"

- Describe the data set: what are the columns and units? Where do the numbers come from? 
- What is the temporal resolution of the data? 
- Read in and prepare data for analysis.   
- Reverse the ordering to create a chronological record so that each measurement is associcated with calender year.
- Plot data.  
- Combine this time series with the Mauna Loa data (the Warm-up exercise in this assignment).  You will use "bind_rows()".
- Plot the combined data. (the most recent time period must be on the right side of the plot).        
- Describe your conclusions to the question "How do recent atmospheric CO2 levels compare to historical levels?" using your plot as supporting evidence.   

**Answer 10:**

The data set provides CO2 concentrations from up to 400,000 years ago which allows us to study long term climate patterns. It captures natural fluctuations atmospheric CO₂ over prehistoric times, long before human industrial activity. In contrast, the Mauna Loa dataset records modern CO₂ levels from the 1950s to today, offering precise measurements of how atmospheric CO₂ has changed in recent decades. Both datasets measure CO₂ concentration in parts per million (ppm), making it possible to directly compare historical and modern levels to understand long-term trends and recent human impacts.


```{r}
library(readr)

# Read the file, skipping metadata rows
vostok_data <- read_table("~/Desktop/Environmental Data Science/assignment-3-ethanp07/assignment/vostok.icecore.co2", skip = 20, col_names = c("Depth_m", "Age_ice_yrBP", "Age_air_yrBP", "CO2_ppm"))

# Reverse the order for chronological plotting
vostok_data <- vostok_data %>% arrange(Age_air_yrBP)

ggplot(vostok_data, aes(x = Age_air_yrBP, y = CO2_ppm)) +
  geom_line(color = "blue") +
  labs(title = "Vostok Ice Core CO2 Levels Over Time",
       x = "Age of Air (years before present)",
       y = "CO₂ Concentration (ppm)") +
  theme_minimal()

```

```{r}
# --- Load and Process Mauna Loa Data ---
mauna_loa_data <- read_table(
  "https://gml.noaa.gov/webdata/ccgg/trends/co2/co2_mm_mlo.txt", 
  skip = 72, 
  col_names = FALSE
)

# Rename columns (adjust if needed based on file structure)
colnames(mauna_loa_data) <- c("Year", "CO2_ppm", "Extra1", "Extra2", "Extra3")

# Keep only relevant columns and convert to "years before present"
mauna_loa_data <- mauna_loa_data %>%
  select(Year, CO2_ppm) %>%
  mutate(Year = as.numeric(Year),
         # Here we assume "present" is 2025. Adjust if needed.
         Age_air_yrBP = 2025 - Year) %>%  
  select(Age_air_yrBP, CO2_ppm)

# For consistency, select the same columns from Vostok data
vostok_subset <- vostok_data %>% select(Age_air_yrBP, CO2_ppm)

# Combine the historical and modern CO₂ data
combined_co2 <- bind_rows(vostok_subset, mauna_loa_data)

ggplot() +
  # Plot Vostok (historical) data in blue
  geom_line(data = vostok_subset, aes(x = Age_air_yrBP, y = CO2_ppm, color = "Historical (Vostok)"), size = 1) +
  # Plot Mauna Loa (modern) data in red
  geom_line(data = mauna_loa_data, aes(x = Age_air_yrBP, y = CO2_ppm, color = "Modern (Mauna Loa)"), size = 1.2) +
  # Manually set colors
  scale_color_manual(values = c("Historical (Vostok)" = "blue", "Modern (Mauna Loa)" = "red")) +
  # Reverse x-axis so that the most recent time (i.e., near 0 years BP) appears on the right
  scale_x_reverse() +
  labs(title = "CO₂ Concentration Over Time: Historical vs. Modern Data",
       x = "Age of Air (years before present)",
       y = "CO₂ Concentration (ppm)",
       caption = "Data Sources: Vostok Ice Core & Mauna Loa (NOAA)",
       color = "Data Source") +
  theme_minimal()
```
 
Recent atmospheric CO₂ levels, as shown by the Mauna Loa data (in red), are significantly higher than any levels recorded in the Vostok ice cores (in blue), which reflect natural fluctuations over the past 400,000 years. The sharp increase in modern CO₂ concentrations, now exceeding 400 ppm, is unprecedented, with the historical record never surpassing 300 ppm. This rapid rise is strongly indicative of human activities, particularly fossil fuel combustion, driving significant changes in Earth's atmosphere and contributing to climate change. Over hundreds of thousands of years, the Vostok ice core record shows atmospheric CO₂ concentrations fluctuating but remaining generally below 300 ppm. In contrast, recent Mauna Loa measurements exceed 400 ppm, revealing a sharp and unprecedented rise. This rapid increase highlights the significant impact of modern human activities on atmospheric CO₂ levels.

# Render and committing

Remember to Render your document as HTML and comment+push to GitHub your code and rendered HTML that was created when you knitted the document.  Your GitHub repository should have multiple commits with informative commit messages.

# Attribution

Include citation of any AI-generated assistance or discussion with classmates (per policy in syllabus). Proper documentation of AI-generated assistance includes the prompt, the source (e.g., ChatGPT), and the significant parts of the response.  Proper documentation of discussion with classmates include listing their names and the components discussed.  

I used ChatGPT to help with question 6 and 7 and for some commenting of my code in the assignment

